{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy and monitor a machine learning workflow for Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up this notebook\n",
    "\n",
    "Notes about the instance size and kernel setup: this notebook has been tested on\n",
    "\n",
    "1. The `Python 3 (Data Science)` kernel\n",
    "2. The `ml.t3.medium` Sagemaker notebook instance\n",
    "\n",
    "## Data Staging\n",
    "\n",
    "We'll use a sample dataset called CIFAR to simulate the challenges Scones Unlimited are facing in Image Classification. In order to start working with CIFAR we'll need to:\n",
    "\n",
    "1. Extract the data from a hosting service\n",
    "2. Transform it into a usable shape and format\n",
    "3. Load it into a production system\n",
    "\n",
    "In other words, we're going to do some simple ETL!\n",
    "\n",
    "### 1. Extract the data from the hosting service\n",
    "\n",
    "In the cell below, define a function `extract_cifar_data` that extracts python version of the CIFAR-100 dataset. The CIFAR dataaset is open source and generously hosted by the University of Toronto at: https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def extract_cifar_data(url, filename=\"cifar.tar.gz\"):\n",
    "    \"\"\"A function for extracting the CIFAR-100 dataset and storing it as a gzipped file\n",
    "    \n",
    "    Arguments:\n",
    "    url      -- the URL where the dataset is hosted\n",
    "    filename -- the full path where the dataset will be written\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Todo: request the data from the data url\n",
    "    # Hint: use `requests.get` method\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    with open(filename, \"wb\") as file_context:\n",
    "        file_context.write(r.content)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it out! Run the following cell and check whether a new file `cifar.tar.gz` is created in the file explorer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_cifar_data(\"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\")     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Transform the data into a usable shape and format\n",
    "\n",
    "Clearly, distributing the data as a gzipped archive makes sense for the hosting service! It saves on bandwidth, storage, and it's a widely-used archive format. In fact, it's so widely used that the Python community ships a utility for working with them, `tarfile`, as part of its Standard Library. Execute the following cell to decompress your extracted dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "with tarfile.open(\"cifar.tar.gz\", \"r:gz\") as tar:\n",
    "    tar.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new folder `cifar-100-python` should be created, containing `meta`, `test`, and `train` files. These files are `pickles` and the [CIFAR homepage](https://www.cs.toronto.edu/~kriz/cifar.html) provides a simple script that can be used to load them. We've adapted the script below for you to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./cifar-100-python/meta\", \"rb\") as f:\n",
    "    dataset_meta = pickle.load(f, encoding='bytes')\n",
    "\n",
    "with open(\"./cifar-100-python/test\", \"rb\") as f:\n",
    "    dataset_test = pickle.load(f, encoding='bytes')\n",
    "\n",
    "with open(\"./cifar-100-python/train\", \"rb\") as f:\n",
    "    dataset_train = pickle.load(f, encoding='bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([b'filenames', b'batch_label', b'fine_labels', b'coarse_labels', b'data'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feel free to explore the datasets\n",
    "dataset_train.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As documented on the homepage, `b'data'` contains rows of 3073 unsigned integers, representing three channels (red, green, and blue) for one 32x32 pixel image per row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 97,  93,  94, ..., 113, 112, 100], dtype=uint8)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[b'data'][90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*32*3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a simple gut-check, let's transform one of our images. Each 1024 items in a row is a channel (red, green, then blue). Each 32 items in the channel are a row in the 32x32 image. Using python, we can stack these channels into a 32x32x3 array, and save it as a PNG file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Each 1024 in a row is a channel (red, green, then blue)\n",
    "row = dataset_train[b'data'][0]\n",
    "red, green, blue = row[0:1024], row[1024:2048], row[2048:]\n",
    "\n",
    "# Each 32 items in the channel are a row in the 32x32 image\n",
    "red = red.reshape(32,32)\n",
    "green = green.reshape(32,32)\n",
    "blue = blue.reshape(32,32)\n",
    "\n",
    "# Combine the channels into a 32x32x3 image!\n",
    "combined = np.dstack((red,green,blue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a more concise version, consider the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All in one:\n",
    "test_image = np.dstack((\n",
    "    row[0:1024].reshape(32,32),\n",
    "    row[1024:2048].reshape(32,32),\n",
    "    row[2048:].reshape(32,32)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(test_image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a cow! Let's check the label. `dataset_meta` contains label names in order, and `dataset_train` has a list of labels for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[b'fine_labels'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our image has a label of `19`, so let's see what the 19th item is in the list of label names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'cattle'\n"
     ]
    }
   ],
   "source": [
    "print(dataset_meta[b'fine_label_names'][19])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! 'cattle' sounds about right. By the way, using the previous two lines we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'cattle'\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "print(dataset_meta[b'fine_label_names'][dataset_train[b'fine_labels'][n]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know how to check labels, is there a way that we can also check file names? `dataset_train` also contains a `b'filenames'` key. Let's see what we have here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'bos_taurus_s_000507.png'\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train[b'filenames'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Taurus\" is the name of a subspecies of cattle, so this looks like a pretty reasonable filename. To save an image we can also do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave(\"file.png\", test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your new PNG file should now appear in the file explorer -- go ahead and pop it open to see!\n",
    "\n",
    "Now that you know how to reshape the images, save them as files, and capture their filenames and labels, let's just capture all the bicycles and motorcycles and save them. Scones Unlimited can use a model that tells these apart to route delivery drivers automatically.\n",
    "\n",
    "In the following cell, identify the label numbers for Bicycles and Motorcycles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Todo: Filter the dataset_train and dataset_meta objects to find the label numbers for Bicycle and Motorcycles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good job! We only need objects with label 8 and 48 -- this drastically simplifies our handling of the data! Below we construct a dataframe for you, and you can safely drop the rows that don't contain observations about bicycles and motorcycles. Fill in the missing lines below to drop all other rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct the dataframe\n",
    "df_train = pd.DataFrame({\n",
    "    \"filenames\": dataset_train[b'filenames'],\n",
    "    \"labels\": dataset_train[b'fine_labels'],\n",
    "    \"row\": range(len(dataset_train[b'filenames']))\n",
    "})\n",
    "\n",
    "# Drop all rows from df_train where label is not 8 or 48\n",
    "df_train = df_train.loc[df_train['labels'].isin([8,48])]  #TODO: Fill in\n",
    "\n",
    "# Decode df_train.filenames so they are regular strings\n",
    "df_train[\"filenames\"] = df_train[\"filenames\"].apply(\n",
    "    lambda x: x.decode(\"utf-8\")\n",
    ")\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    \"filenames\": dataset_test[b'filenames'],\n",
    "    \"labels\": dataset_test[b'fine_labels'],\n",
    "    \"row\": range(len(dataset_test[b'filenames']))\n",
    "})\n",
    "\n",
    "# Drop all rows from df_test where label is not 8 or 48\n",
    "df_test = df_test.loc[df_test['labels'].isin([8,48])]  #TODO: Fill in#TODO: Fill in\n",
    "\n",
    "# Decode df_test.filenames so they are regular strings\n",
    "df_test[\"filenames\"] = df_test[\"filenames\"].apply(\n",
    "    lambda x: x.decode(\"utf-8\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is filtered for just our classes, we can save all our images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./train\n",
    "!mkdir ./test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous sections we introduced you to several key snippets of code:\n",
    "\n",
    "1. Grabbing the image data:\n",
    "\n",
    "```python\n",
    "dataset_train[b'data'][0]\n",
    "```\n",
    "\n",
    "2. A simple idiom for stacking the image data into the right shape\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "np.dstack((\n",
    "    row[0:1024].reshape(32,32),\n",
    "    row[1024:2048].reshape(32,32),\n",
    "    row[2048:].reshape(32,32)\n",
    "))\n",
    "```\n",
    "\n",
    "3. A simple `matplotlib` utility for saving images\n",
    "\n",
    "```python\n",
    "plt.imsave(path+row['filenames'], target)\n",
    "```\n",
    "\n",
    "Compose these together into a function that saves all the images into the `./test` and `./train` directories. Use the comments in the body of the `save_images` function below to guide your construction of the function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 10000)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(dataset_test[b'data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def save_images(save_path, data):\n",
    "\n",
    "    #Grab the image data in row-major form\n",
    "    for i in range(len(data[b'data'])):\n",
    "        img = data[b'data'][i]\n",
    "        filename = data[b'filenames'][i].decode(\"utf-8\")\n",
    "\n",
    "        # Consolidated stacking/reshaping from earlier\n",
    "        target = np.dstack((\n",
    "        img[0:1024].reshape(32,32),\n",
    "        img[1024:2048].reshape(32,32),\n",
    "        img[2048:].reshape(32,32)\n",
    "            ))\n",
    "        #save image\n",
    "        plt.imsave(save_path+filename, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: save ALL images using the save_images function\n",
    "save_images('./train/', dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images('./test/', dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load the data\n",
    "\n",
    "Now we can load the data into S3.\n",
    "\n",
    "Using the sagemaker SDK grab the current region, execution role, and bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Bucket: sagemaker-us-east-1-054619787751\n",
      "AWS Region: us-east-1\n",
      "RoleArn: arn:aws:iam::054619787751:role/service-role/AmazonSageMaker-ExecutionRole-20220924T123284\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "session = Session()\n",
    "\n",
    "bucket = session.default_bucket() ## TODO: fill in\n",
    "print(\"Default Bucket: {}\".format(bucket))\n",
    "\n",
    "region = session.boto_region_name ## TODO: fill in\n",
    "print(\"AWS Region: {}\".format(region))\n",
    "\n",
    "role = get_execution_role() ## TODO: fill in\n",
    "print(\"RoleArn: {}\".format(role))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this data we can easily sync your data up into S3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DEFAULT_S3_BUCKET\"] = bucket\n",
    "!aws s3 sync ./train s3://${DEFAULT_S3_BUCKET}/train/\n",
    "!aws s3 sync ./test s3://${DEFAULT_S3_BUCKET}/test/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! You can check the bucket and verify that the items were uploaded.\n",
    "\n",
    "## Model Training\n",
    "\n",
    "For Image Classification, Sagemaker [also expects metadata](https://docs.aws.amazon.com/sagemaker/latest/dg/image-classification.html) e.g. in the form of TSV files with labels and filepaths. We can generate these using our Pandas DataFrames from earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_metadata_file(df, prefix):\n",
    "    df[\"s3_path\"] = df[\"filenames\"]\n",
    "    df[\"labels\"] = df[\"labels\"].apply(lambda x: 0 if x==8 else 1)\n",
    "    return df[[\"row\", \"labels\", \"s3_path\"]].to_csv(\n",
    "        f\"{prefix}.lst\", sep=\"\\t\", index=False, header=False\n",
    "    )\n",
    "    \n",
    "to_metadata_file(df_train.copy(), \"train\")\n",
    "to_metadata_file(df_test.copy(), \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also upload our manifest files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Upload files\n",
    "boto3.Session().resource('s3').Bucket(\n",
    "    bucket).Object('train.lst').upload_file('./train.lst')\n",
    "boto3.Session().resource('s3').Bucket(\n",
    "    bucket).Object('test.lst').upload_file('./test.lst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `bucket` and `region` info we can get the latest prebuilt container to run our training job, and define an output location on our s3 bucket for the model. Use the `image_uris` function from the SageMaker SDK to retrieve the latest `image-classification` image below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n"
     ]
    }
   ],
   "source": [
    "# Use the image_uris function to retrieve the latest 'image-classification' image \n",
    "from sagemaker import image_uris\n",
    "algo_image = image_uris.retrieve('image-classification', region, version='latest') ## TODO: fill in\n",
    "s3_output_location = f\"s3://{bucket}/models/image_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're ready to create an estimator! Create an estimator `img_classifier_model` that uses one instance of `ml.p3.2xlarge`. Ensure that you use the output location we defined above - we'll be referring to that later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_classifier_model=sagemaker.estimator.Estimator(\n",
    "    ## TODO: define your estimator options\n",
    "    image_uri=algo_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    volume_size=5,\n",
    "    output_path=s3_output_location,\n",
    "    sagemaker_session=session    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also set a few key hyperparameters and define the inputs for our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_classifier_model.set_hyperparameters(\n",
    "    image_shape='3,32,32', # TODO: Fill in\n",
    "    num_classes=2, # TODO: Fill in\n",
    "    num_training_samples=50000 # TODO: fill in\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `image-classification` image uses four input channels with very specific input parameters. For convenience, we've provided them below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import Rule, rule_configs\n",
    "from sagemaker.session import TrainingInput\n",
    "model_inputs = {\n",
    "        \"train\": sagemaker.inputs.TrainingInput(\n",
    "            s3_data=f\"s3://{bucket}/train/\",\n",
    "            content_type=\"application/x-image\"\n",
    "        ),\n",
    "        \"validation\": sagemaker.inputs.TrainingInput(\n",
    "            s3_data=f\"s3://{bucket}/test/\",\n",
    "            content_type=\"application/x-image\"\n",
    "        ),\n",
    "        \"train_lst\": sagemaker.inputs.TrainingInput(\n",
    "            s3_data=f\"s3://{bucket}/train.lst\",\n",
    "            content_type=\"application/x-image\"\n",
    "        ),\n",
    "        \"validation_lst\": sagemaker.inputs.TrainingInput(\n",
    "            s3_data=f\"s3://{bucket}/test.lst\",\n",
    "            content_type=\"application/x-image\"\n",
    "        )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Estimator in module sagemaker.estimator object:\n",
      "\n",
      "class Estimator(EstimatorBase)\n",
      " |  Estimator(image_uri: Union[str, sagemaker.workflow.entities.PipelineVariable], role: str, instance_count: Union[int, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, instance_type: Union[str, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, volume_size: Union[int, sagemaker.workflow.entities.PipelineVariable] = 30, volume_kms_key: Union[str, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, max_run: Union[int, sagemaker.workflow.entities.PipelineVariable] = 86400, input_mode: Union[str, sagemaker.workflow.entities.PipelineVariable] = 'File', output_path: Union[str, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, output_kms_key: Union[str, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, base_job_name: Union[str, NoneType] = None, sagemaker_session: Union[sagemaker.session.Session, NoneType] = None, hyperparameters: Union[Dict[str, Union[str, sagemaker.workflow.entities.PipelineVariable]], NoneType] = None, tags: Union[List[Dict[str, Union[str, sagemaker.workflow.entities.PipelineVariable]]], NoneType] = None, subnets: Union[List[Union[str, sagemaker.workflow.entities.PipelineVariable]], NoneType] = None, security_group_ids: Union[List[Union[str, sagemaker.workflow.entities.PipelineVariable]], NoneType] = None, model_uri: Union[str, NoneType] = None, model_channel_name: Union[str, sagemaker.workflow.entities.PipelineVariable] = 'model', metric_definitions: Union[List[Dict[str, Union[str, sagemaker.workflow.entities.PipelineVariable]]], NoneType] = None, encrypt_inter_container_traffic: Union[bool, sagemaker.workflow.entities.PipelineVariable] = False, use_spot_instances: Union[bool, sagemaker.workflow.entities.PipelineVariable] = False, max_wait: Union[int, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, checkpoint_s3_uri: Union[str, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, checkpoint_local_path: Union[str, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, enable_network_isolation: Union[bool, sagemaker.workflow.entities.PipelineVariable] = False, rules: Union[List[sagemaker.debugger.debugger.RuleBase], NoneType] = None, debugger_hook_config: Union[bool, sagemaker.debugger.debugger.DebuggerHookConfig, NoneType] = None, tensorboard_output_config: Union[sagemaker.debugger.debugger.TensorBoardOutputConfig, NoneType] = None, enable_sagemaker_metrics: Union[bool, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, profiler_config: Union[sagemaker.debugger.profiler_config.ProfilerConfig, NoneType] = None, disable_profiler: bool = False, environment: Union[Dict[str, Union[str, sagemaker.workflow.entities.PipelineVariable]], NoneType] = None, max_retry_attempts: Union[int, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, source_dir: Union[str, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, git_config: Union[Dict[str, str], NoneType] = None, container_log_level: Union[int, sagemaker.workflow.entities.PipelineVariable] = 20, code_location: Union[str, NoneType] = None, entry_point: Union[str, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, dependencies: Union[List[str], NoneType] = None, instance_groups: Union[List[sagemaker.instance_group.InstanceGroup], NoneType] = None, **kwargs)\n",
      " |  \n",
      " |  A generic Estimator to train using any supplied algorithm.\n",
      " |  \n",
      " |  This class is designed for use with algorithms that don't have their own, custom class.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Estimator\n",
      " |      EstimatorBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, image_uri: Union[str, sagemaker.workflow.entities.PipelineVariable], role: str, instance_count: Union[int, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, instance_type: Union[str, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, volume_size: Union[int, sagemaker.workflow.entities.PipelineVariable] = 30, volume_kms_key: Union[str, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, max_run: Union[int, sagemaker.workflow.entities.PipelineVariable] = 86400, input_mode: Union[str, sagemaker.workflow.entities.PipelineVariable] = 'File', output_path: Union[str, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, output_kms_key: Union[str, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, base_job_name: Union[str, NoneType] = None, sagemaker_session: Union[sagemaker.session.Session, NoneType] = None, hyperparameters: Union[Dict[str, Union[str, sagemaker.workflow.entities.PipelineVariable]], NoneType] = None, tags: Union[List[Dict[str, Union[str, sagemaker.workflow.entities.PipelineVariable]]], NoneType] = None, subnets: Union[List[Union[str, sagemaker.workflow.entities.PipelineVariable]], NoneType] = None, security_group_ids: Union[List[Union[str, sagemaker.workflow.entities.PipelineVariable]], NoneType] = None, model_uri: Union[str, NoneType] = None, model_channel_name: Union[str, sagemaker.workflow.entities.PipelineVariable] = 'model', metric_definitions: Union[List[Dict[str, Union[str, sagemaker.workflow.entities.PipelineVariable]]], NoneType] = None, encrypt_inter_container_traffic: Union[bool, sagemaker.workflow.entities.PipelineVariable] = False, use_spot_instances: Union[bool, sagemaker.workflow.entities.PipelineVariable] = False, max_wait: Union[int, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, checkpoint_s3_uri: Union[str, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, checkpoint_local_path: Union[str, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, enable_network_isolation: Union[bool, sagemaker.workflow.entities.PipelineVariable] = False, rules: Union[List[sagemaker.debugger.debugger.RuleBase], NoneType] = None, debugger_hook_config: Union[bool, sagemaker.debugger.debugger.DebuggerHookConfig, NoneType] = None, tensorboard_output_config: Union[sagemaker.debugger.debugger.TensorBoardOutputConfig, NoneType] = None, enable_sagemaker_metrics: Union[bool, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, profiler_config: Union[sagemaker.debugger.profiler_config.ProfilerConfig, NoneType] = None, disable_profiler: bool = False, environment: Union[Dict[str, Union[str, sagemaker.workflow.entities.PipelineVariable]], NoneType] = None, max_retry_attempts: Union[int, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, source_dir: Union[str, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, git_config: Union[Dict[str, str], NoneType] = None, container_log_level: Union[int, sagemaker.workflow.entities.PipelineVariable] = 20, code_location: Union[str, NoneType] = None, entry_point: Union[str, sagemaker.workflow.entities.PipelineVariable, NoneType] = None, dependencies: Union[List[str], NoneType] = None, instance_groups: Union[List[sagemaker.instance_group.InstanceGroup], NoneType] = None, **kwargs)\n",
      " |      Initialize an ``Estimator`` instance.\n",
      " |      \n",
      " |      Args:\n",
      " |          image_uri (str): The container image to use for training.\n",
      " |          role (str): An AWS IAM role (either name or full ARN). The Amazon\n",
      " |              SageMaker training jobs and APIs that create Amazon SageMaker\n",
      " |              endpoints use this role to access training data and model\n",
      " |              artifacts. After the endpoint is created, the inference code\n",
      " |              might use the IAM role, if it needs to access an AWS resource.\n",
      " |          instance_count (int): Number of Amazon EC2 instances to use\n",
      " |              for training. Required if instance_groups is not set.\n",
      " |          instance_type (str): Type of EC2 instance to use for training,\n",
      " |              for example, 'ml.c4.xlarge'. Required if instance_groups is\n",
      " |              not set.\n",
      " |          volume_size (int): Size in GB of the EBS volume to use for\n",
      " |              storing input data during training (default: 30). Must be large\n",
      " |              enough to store training data if File Mode is used (which is the\n",
      " |              default).\n",
      " |          volume_kms_key (str): Optional. KMS key ID for encrypting EBS\n",
      " |              volume attached to the training instance (default: None).\n",
      " |          max_run (int): Timeout in seconds for training (default: 24 *\n",
      " |              60 * 60). After this amount of time Amazon SageMaker terminates\n",
      " |              the job regardless of its current status.\n",
      " |          input_mode (str): The input mode that the algorithm supports\n",
      " |              (default: 'File'). Valid modes:\n",
      " |      \n",
      " |              * 'File' - Amazon SageMaker copies the training dataset from the\n",
      " |                S3 location to a local directory.\n",
      " |              * 'Pipe' - Amazon SageMaker streams data directly from S3 to the\n",
      " |                container via a Unix-named pipe.\n",
      " |      \n",
      " |              This argument can be overriden on a per-channel basis using\n",
      " |              ``sagemaker.inputs.TrainingInput.input_mode``.\n",
      " |          output_path (str): S3 location for saving the training result (model\n",
      " |              artifacts and output files). If not specified, results are\n",
      " |              stored to a default bucket. If the bucket with the specific name\n",
      " |              does not exist, the estimator creates the bucket during the\n",
      " |              :meth:`~sagemaker.estimator.EstimatorBase.fit` method execution.\n",
      " |          output_kms_key (str): Optional. KMS key ID for encrypting the\n",
      " |              training output (default: None).\n",
      " |          base_job_name (str): Prefix for training job name when the\n",
      " |              :meth:`~sagemaker.estimator.EstimatorBase.fit` method launches.\n",
      " |              If not specified, the estimator generates a default job name,\n",
      " |              based on the training image name and current timestamp.\n",
      " |          sagemaker_session (sagemaker.session.Session): Session object which\n",
      " |              manages interactions with Amazon SageMaker APIs and any other\n",
      " |              AWS services needed. If not specified, the estimator creates one\n",
      " |              using the default AWS configuration chain.\n",
      " |          hyperparameters (dict): Dictionary containing the hyperparameters to\n",
      " |              initialize this estimator with.\n",
      " |          tags (list[dict]): List of tags for labeling a training job. For\n",
      " |              more, see\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/API_Tag.html.\n",
      " |          subnets (list[str]): List of subnet ids. If not specified training\n",
      " |              job will be created without VPC config.\n",
      " |          security_group_ids (list[str]): List of security group ids. If not\n",
      " |              specified training job will be created without VPC config.\n",
      " |          model_uri (str): URI where a pre-trained model is stored, either\n",
      " |              locally or in S3 (default: None). If specified, the estimator\n",
      " |              will create a channel pointing to the model so the training job\n",
      " |              can download it. This model can be a 'model.tar.gz' from a\n",
      " |              previous training job, or other artifacts coming from a\n",
      " |              different source.\n",
      " |      \n",
      " |              In local mode, this should point to the path in which the model\n",
      " |              is located and not the file itself, as local Docker containers\n",
      " |              will try to mount the URI as a volume.\n",
      " |      \n",
      " |              More information:\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html#td-deserialization\n",
      " |          model_channel_name (str): Name of the channel where 'model_uri' will\n",
      " |              be downloaded (default: 'model').\n",
      " |          metric_definitions (list[dict]): A list of dictionaries that defines\n",
      " |              the metric(s) used to evaluate the training jobs. Each\n",
      " |              dictionary contains two keys: 'Name' for the name of the metric,\n",
      " |              and 'Regex' for the regular expression used to extract the\n",
      " |              metric from the logs. This should be defined only for jobs that\n",
      " |              don't use an Amazon algorithm.\n",
      " |          encrypt_inter_container_traffic (bool): Specifies whether traffic\n",
      " |              between training containers is encrypted for the training job\n",
      " |              (default: ``False``).\n",
      " |          use_spot_instances (bool): Specifies whether to use SageMaker\n",
      " |              Managed Spot instances for training. If enabled then the\n",
      " |              ``max_wait`` arg should also be set.\n",
      " |      \n",
      " |              More information:\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html\n",
      " |              (default: ``False``).\n",
      " |          max_wait (int): Timeout in seconds waiting for spot training\n",
      " |              job (default: None). After this amount of time Amazon\n",
      " |              SageMaker will stop waiting for managed spot training job to\n",
      " |              complete (default: None).\n",
      " |          checkpoint_s3_uri (str): The S3 URI in which to persist checkpoints\n",
      " |              that the algorithm persists (if any) during training. (default:\n",
      " |              None).\n",
      " |          checkpoint_local_path (str): The local path that the algorithm\n",
      " |              writes its checkpoints to. SageMaker will persist all files\n",
      " |              under this path to `checkpoint_s3_uri` continually during\n",
      " |              training. On job startup the reverse happens - data from the\n",
      " |              s3 location is downloaded to this path before the algorithm is\n",
      " |              started. If the path is unset then SageMaker assumes the\n",
      " |              checkpoints will be provided under `/opt/ml/checkpoints/`.\n",
      " |              (default: None).\n",
      " |          enable_network_isolation (bool): Specifies whether container will\n",
      " |              run in network isolation mode (default: ``False``). Network\n",
      " |              isolation mode restricts the container access to outside networks\n",
      " |              (such as the Internet). The container does not make any inbound or\n",
      " |              outbound network calls. Also known as Internet-free mode.\n",
      " |          rules (list[:class:`~sagemaker.debugger.RuleBase`]): A list of\n",
      " |              :class:`~sagemaker.debugger.RuleBase` objects used to define\n",
      " |              SageMaker Debugger rules for real-time analysis\n",
      " |              (default: None). For more information,\n",
      " |              see `Continuous analyses through rules\n",
      " |              <https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_debugger.html\n",
      " |              #continuous-analyses-through-rules)>`_.\n",
      " |          debugger_hook_config (:class:`~sagemaker.debugger.DebuggerHookConfig` or bool):\n",
      " |              Configuration for how debugging information is emitted with\n",
      " |              SageMaker Debugger. If not specified, a default one is created using\n",
      " |              the estimator's ``output_path``, unless the region does not\n",
      " |              support SageMaker Debugger. To disable SageMaker Debugger,\n",
      " |              set this parameter to ``False``. For more information, see\n",
      " |              `Capture real-time debugging data during model training in Amazon SageMaker\n",
      " |              <https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_debugger.html#\n",
      " |              capture-real-time-debugging-data-during-model-training-in-amazon-sagemaker>`_.\n",
      " |          tensorboard_output_config (:class:`~sagemaker.debugger.TensorBoardOutputConfig`):\n",
      " |              Configuration for customizing debugging visualization using TensorBoard\n",
      " |              (default: None). For more information,\n",
      " |              see `Capture real time tensorboard data\n",
      " |              <https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_debugger.html#\n",
      " |              capture-real-time-tensorboard-data-from-the-debugging-hook>`_.\n",
      " |          enable_sagemaker_metrics (bool): enable SageMaker Metrics Time\n",
      " |              Series. For more information, see `AlgorithmSpecification API\n",
      " |              <https://docs.aws.amazon.com/sagemaker/latest/dg/\n",
      " |              API_AlgorithmSpecification.html#SageMaker-Type-AlgorithmSpecification-\n",
      " |              EnableSageMakerMetricsTimeSeries>`_.\n",
      " |              (default: None).\n",
      " |          profiler_config (:class:`~sagemaker.debugger.ProfilerConfig`):\n",
      " |              Configuration for how SageMaker Debugger collects\n",
      " |              monitoring and profiling information from your training job.\n",
      " |              If not specified, Debugger will be configured with\n",
      " |              a default configuration and will save system and framework metrics\n",
      " |              the estimator's default ``output_path`` in Amazon S3.\n",
      " |              Use :class:`~sagemaker.debugger.ProfilerConfig` to configure this parameter.\n",
      " |              To disable SageMaker Debugger monitoring and profiling, set the\n",
      " |              ``disable_profiler`` parameter to ``True``.\n",
      " |          disable_profiler (bool): Specifies whether Debugger monitoring and profiling\n",
      " |              will be disabled (default: ``False``).\n",
      " |          environment (dict[str, str]) : Environment variables to be set for\n",
      " |              use during training job (default: None)\n",
      " |          max_retry_attempts (int): The number of times to move a job to the STARTING status.\n",
      " |              You can specify between 1 and 30 attempts.\n",
      " |              If the value of attempts is greater than zero,\n",
      " |              the job is retried on InternalServerFailure\n",
      " |              the same number of attempts as the value.\n",
      " |              You can cap the total duration for your job by setting ``max_wait`` and ``max_run``\n",
      " |              (default: None)\n",
      " |          source_dir (str): The absolute, relative, or S3 URI Path to a directory\n",
      " |              with any other training source code dependencies aside from the entry\n",
      " |              point file (default: None). If ``source_dir`` is an S3 URI, it must\n",
      " |              point to a tar.gz file. Structure within this directory is preserved\n",
      " |              when training on Amazon SageMaker. If 'git_config' is provided,\n",
      " |              'source_dir' should be a relative location to a directory in the Git\n",
      " |              repo.\n",
      " |      \n",
      " |              .. admonition:: Example\n",
      " |      \n",
      " |                  With the following GitHub repo directory structure:\n",
      " |      \n",
      " |                  >>> |----- README.md\n",
      " |                  >>> |----- src\n",
      " |                  >>>         |----- train.py\n",
      " |                  >>>         |----- test.py\n",
      " |      \n",
      " |                  if you need 'train.py'\n",
      " |                  as the entry point and 'test.py' as the training source code, you can assign\n",
      " |                  entry_point='train.py', source_dir='src'.\n",
      " |          git_config (dict[str, str]): Git configurations used for cloning\n",
      " |              files, including ``repo``, ``branch``, ``commit``,\n",
      " |              ``2FA_enabled``, ``username``, ``password`` and ``token``. The\n",
      " |              ``repo`` field is required. All other fields are optional.\n",
      " |              ``repo`` specifies the Git repository where your training script\n",
      " |              is stored. If you don't provide ``branch``, the default value\n",
      " |              'master' is used. If you don't provide ``commit``, the latest\n",
      " |              commit in the specified branch is used.\n",
      " |      \n",
      " |              .. admonition:: Example\n",
      " |      \n",
      " |                  The following config:\n",
      " |      \n",
      " |                  >>> git_config = {'repo': 'https://github.com/aws/sagemaker-python-sdk.git',\n",
      " |                  >>>               'branch': 'test-branch-git-config',\n",
      " |                  >>>               'commit': '329bfcf884482002c05ff7f44f62599ebc9f445a'}\n",
      " |      \n",
      " |                  results in cloning the repo specified in 'repo', then\n",
      " |                  checking out the 'master' branch, and checking out the specified\n",
      " |                  commit.\n",
      " |      \n",
      " |              ``2FA_enabled``, ``username``, ``password`` and ``token`` are\n",
      " |              used for authentication. For GitHub (or other Git) accounts, set\n",
      " |              ``2FA_enabled`` to 'True' if two-factor authentication is\n",
      " |              enabled for the account, otherwise set it to 'False'. If you do\n",
      " |              not provide a value for ``2FA_enabled``, a default value of\n",
      " |              'False' is used. CodeCommit does not support two-factor\n",
      " |              authentication, so do not provide \"2FA_enabled\" with CodeCommit\n",
      " |              repositories.\n",
      " |      \n",
      " |              For GitHub and other Git repos, when SSH URLs are provided, it\n",
      " |              doesn't matter whether 2FA is enabled or disabled. You should\n",
      " |              either have no passphrase for the SSH key pairs or have the\n",
      " |              ssh-agent configured so that you will not be prompted for the SSH\n",
      " |              passphrase when you run the 'git clone' command with SSH URLs. When\n",
      " |              HTTPS URLs are provided, if 2FA is disabled, then either ``token``\n",
      " |              or ``username`` and ``password`` are be used for authentication if provided.\n",
      " |              ``Token`` is prioritized. If 2FA is enabled, only ``token`` is used\n",
      " |              for authentication if provided. If required authentication info\n",
      " |              is not provided, the SageMaker Python SDK attempts to use local credentials\n",
      " |              to authenticate. If that fails, an error message is thrown.\n",
      " |      \n",
      " |              For CodeCommit repos, 2FA is not supported, so ``2FA_enabled``\n",
      " |              should not be provided. There is no token in CodeCommit, so\n",
      " |              ``token`` should also not be provided. When ``repo`` is an SSH URL,\n",
      " |              the requirements are the same as GitHub  repos. When ``repo``\n",
      " |              is an HTTPS URL, ``username`` and ``password`` are used for\n",
      " |              authentication if they are provided. If they are not provided,\n",
      " |              the SageMaker Python SDK attempts to use either the CodeCommit\n",
      " |              credential helper or local credential storage for authentication.\n",
      " |          container_log_level (int): The log level to use within the container\n",
      " |              (default: logging.INFO). Valid values are defined in the Python\n",
      " |              logging module.\n",
      " |          code_location (str): The S3 prefix URI where custom code is\n",
      " |              uploaded (default: None). You must not include a trailing slash because\n",
      " |              a string prepended with a \"/\" is appended to ``code_location``. The code\n",
      " |              file uploaded to S3 is 'code_location/job-name/source/sourcedir.tar.gz'.\n",
      " |              If not specified, the default ``code location`` is 's3://output_bucket/job-name/'.\n",
      " |          entry_point (str): The absolute or relative path to the local Python\n",
      " |              source file that should be executed as the entry point to\n",
      " |              training. If ``source_dir`` is specified, then ``entry_point``\n",
      " |              must point to a file located at the root of ``source_dir``.\n",
      " |              If 'git_config' is provided, 'entry_point' should be\n",
      " |              a relative location to the Python source file in the Git repo.\n",
      " |      \n",
      " |              Example:\n",
      " |                  With the following GitHub repo directory structure:\n",
      " |      \n",
      " |                  >>> |----- README.md\n",
      " |                  >>> |----- src\n",
      " |                  >>>         |----- train.py\n",
      " |                  >>>         |----- test.py\n",
      " |      \n",
      " |                  You can assign entry_point='src/train.py'.\n",
      " |          dependencies (list[str]): A list of absolute or relative paths to directories\n",
      " |              with any additional libraries that should be exported\n",
      " |              to the container (default: []). The library folders are\n",
      " |              copied to SageMaker in the same folder where the entrypoint is\n",
      " |              copied. If 'git_config' is provided, 'dependencies' should be a\n",
      " |              list of relative locations to directories with any additional\n",
      " |              libraries needed in the Git repo.\n",
      " |      \n",
      " |              .. admonition:: Example\n",
      " |      \n",
      " |                  The following Estimator call:\n",
      " |      \n",
      " |                  >>> Estimator(entry_point='train.py',\n",
      " |                  ...           dependencies=['my/libs/common', 'virtual-env'])\n",
      " |      \n",
      " |                  results in the following structure inside the container:\n",
      " |      \n",
      " |                  >>> $ ls\n",
      " |      \n",
      " |                  >>> opt/ml/code\n",
      " |                  >>>     |------ train.py\n",
      " |                  >>>     |------ common\n",
      " |                  >>>     |------ virtual-env\n",
      " |      \n",
      " |              This is not supported with \"local code\" in Local Mode.\n",
      " |          instance_groups (list[:class:`sagemaker.instance_group.InstanceGroup`]):\n",
      " |              Optional. A list of ``InstanceGroup`` objects\n",
      " |              for launching a training job with a heterogeneous cluster.\n",
      " |              For example:\n",
      " |      \n",
      " |              .. code:: python\n",
      " |      \n",
      " |                  instance_groups=[\n",
      " |                      sagemaker.InstanceGroup(\n",
      " |                          'instance_group_name_1', 'ml.p3dn.24xlarge', 64),\n",
      " |                      sagemaker.InstanceGroup(\n",
      " |                          'instance_group_name_2', 'ml.c5n.18xlarge', 64)]\n",
      " |      \n",
      " |              For instructions on how to use ``InstanceGroup`` objects\n",
      " |              to configure a heterogeneous cluster\n",
      " |              through the SageMaker generic and framework estimator classes, see\n",
      " |              `Train Using a Heterogeneous Cluster\n",
      " |              <https://docs.aws.amazon.com/sagemaker/latest/dg/train-heterogeneous-cluster.html>`_\n",
      " |              in the *Amazon SageMaker developer guide*.\n",
      " |  \n",
      " |  create_model(self, role=None, image_uri=None, predictor_cls=None, vpc_config_override='VPC_CONFIG_DEFAULT', **kwargs)\n",
      " |      Create a model to deploy.\n",
      " |      \n",
      " |      The serializer and deserializer arguments are only used to define a\n",
      " |      default Predictor. They are ignored if an explicit predictor class is passed in.\n",
      " |      Other arguments are passed through to the Model class.\n",
      " |      \n",
      " |      Args:\n",
      " |          role (str): The ``ExecutionRoleArn`` IAM Role ARN for the ``Model``,\n",
      " |              which is also used during transform jobs. If not specified, the\n",
      " |              role from the Estimator will be used.\n",
      " |          image_uri (str): A Docker image URI to use for deploying the model.\n",
      " |              Defaults to the image used for training.\n",
      " |          predictor_cls (Predictor): The predictor class to use when\n",
      " |              deploying the model.\n",
      " |          vpc_config_override (dict[str, list[str]]): Optional override for VpcConfig set on\n",
      " |              the model.\n",
      " |              Default: use subnets and security groups from this Estimator.\n",
      " |              * 'Subnets' (list[str]): List of subnet ids.\n",
      " |              * 'SecurityGroupIds' (list[str]): List of security group ids.\n",
      " |          **kwargs: Additional parameters passed to :class:`~sagemaker.model.Model`\n",
      " |      \n",
      " |      .. tip::\n",
      " |      \n",
      " |          You can find additional parameters for using this method at\n",
      " |          :class:`~sagemaker.model.Model`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (sagemaker.model.Model) a Model ready for deployment.\n",
      " |  \n",
      " |  hyperparameters(self)\n",
      " |      Returns the hyperparameters as a dictionary to use for training.\n",
      " |      \n",
      " |      The fit() method, that does the model training, calls this method to\n",
      " |      find the hyperparameters you specified.\n",
      " |  \n",
      " |  set_hyperparameters(self, **kwargs)\n",
      " |      Sets the hyperparameter dictionary to use for training.\n",
      " |      \n",
      " |      The hyperparameters are made accessible as a dict[str, str] to the\n",
      " |      training code on SageMaker. For convenience, this accepts other types\n",
      " |      for keys and values, but ``str()`` will be called to convert them before\n",
      " |      training.\n",
      " |  \n",
      " |  training_image_uri(self)\n",
      " |      Returns the docker image to use for training.\n",
      " |      \n",
      " |      The fit() method, that does the model training, calls this method to\n",
      " |      find the image to use for model training.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from EstimatorBase:\n",
      " |  \n",
      " |  compile_model(self, target_instance_family, input_shape, output_path, framework=None, framework_version=None, compile_max_run=900, tags=None, target_platform_os=None, target_platform_arch=None, target_platform_accelerator=None, compiler_options=None, **kwargs)\n",
      " |      Compile a Neo model using the input model.\n",
      " |      \n",
      " |      Args:\n",
      " |          target_instance_family (str): Identifies the device that you want to\n",
      " |              run your model after compilation, for example: ml_c5. For allowed\n",
      " |              strings see\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/API_OutputConfig.html.\n",
      " |          input_shape (dict): Specifies the name and shape of the expected\n",
      " |              inputs for your trained model in json dictionary form, for\n",
      " |              example: {'data':[1,3,1024,1024]}, or {'var1': [1,1,28,28],\n",
      " |              'var2':[1,1,28,28]}\n",
      " |          output_path (str): Specifies where to store the compiled model\n",
      " |          framework (str): The framework that is used to train the original\n",
      " |              model. Allowed values: 'mxnet', 'tensorflow', 'keras', 'pytorch',\n",
      " |              'onnx', 'xgboost'\n",
      " |          framework_version (str): The version of the framework\n",
      " |          compile_max_run (int): Timeout in seconds for compilation (default:\n",
      " |              15 * 60). After this amount of time Amazon SageMaker Neo\n",
      " |              terminates the compilation job regardless of its current status.\n",
      " |          tags (list[dict]): List of tags for labeling a compilation job. For\n",
      " |              more, see\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/API_Tag.html.\n",
      " |          target_platform_os (str): Target Platform OS, for example: 'LINUX'.\n",
      " |              For allowed strings see\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/API_OutputConfig.html.\n",
      " |              It can be used instead of target_instance_family.\n",
      " |          target_platform_arch (str): Target Platform Architecture, for example: 'X86_64'.\n",
      " |              For allowed strings see\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/API_OutputConfig.html.\n",
      " |              It can be used instead of target_instance_family.\n",
      " |          target_platform_accelerator (str, optional): Target Platform Accelerator,\n",
      " |              for example: 'NVIDIA'. For allowed strings see\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/API_OutputConfig.html.\n",
      " |              It can be used instead of target_instance_family.\n",
      " |          compiler_options (dict, optional): Additional parameters for compiler.\n",
      " |              Compiler Options are TargetPlatform / target_instance_family specific. See\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/API_OutputConfig.html for details.\n",
      " |          **kwargs: Passed to invocation of ``create_model()``.\n",
      " |              Implementations may customize ``create_model()`` to accept\n",
      " |              ``**kwargs`` to customize model creation during deploy. For\n",
      " |              more, see the implementation docs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          sagemaker.model.Model: A SageMaker ``Model`` object. See\n",
      " |          :func:`~sagemaker.model.Model` for full details.\n",
      " |  \n",
      " |  delete_endpoint = func(*args, **kwargs)\n",
      " |  \n",
      " |  deploy(self, initial_instance_count=None, instance_type=None, serializer=None, deserializer=None, accelerator_type=None, endpoint_name=None, use_compiled_model=False, wait=True, model_name=None, kms_key=None, data_capture_config=None, tags=None, serverless_inference_config=None, async_inference_config=None, **kwargs)\n",
      " |      Deploy the trained model to an Amazon SageMaker endpoint.\n",
      " |      \n",
      " |       And then return ``sagemaker.Predictor`` object.\n",
      " |      \n",
      " |      More information:\n",
      " |      http://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-training.html\n",
      " |      \n",
      " |      Args:\n",
      " |          initial_instance_count (int): The initial number of instances to run\n",
      " |              in the ``Endpoint`` created from this ``Model``. If not using\n",
      " |              serverless inference, then it need to be a number larger or equals\n",
      " |              to 1 (default: None)\n",
      " |          instance_type (str): The EC2 instance type to deploy this Model to.\n",
      " |              For example, 'ml.p2.xlarge', or 'local' for local mode. If not using\n",
      " |              serverless inference, then it is required to deploy a model.\n",
      " |              (default: None)\n",
      " |          serializer (:class:`~sagemaker.serializers.BaseSerializer`): A\n",
      " |              serializer object, used to encode data for an inference endpoint\n",
      " |              (default: None). If ``serializer`` is not None, then\n",
      " |              ``serializer`` will override the default serializer. The\n",
      " |              default serializer is set by the ``predictor_cls``.\n",
      " |          deserializer (:class:`~sagemaker.deserializers.BaseDeserializer`): A\n",
      " |              deserializer object, used to decode data from an inference\n",
      " |              endpoint (default: None). If ``deserializer`` is not None, then\n",
      " |              ``deserializer`` will override the default deserializer. The\n",
      " |              default deserializer is set by the ``predictor_cls``.\n",
      " |          accelerator_type (str): Type of Elastic Inference accelerator to\n",
      " |              attach to an endpoint for model loading and inference, for\n",
      " |              example, 'ml.eia1.medium'. If not specified, no Elastic\n",
      " |              Inference accelerator will be attached to the endpoint. For more\n",
      " |              information:\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html\n",
      " |          endpoint_name (str): Name to use for creating an Amazon SageMaker\n",
      " |              endpoint. If not specified, the name of the training job is\n",
      " |              used.\n",
      " |          use_compiled_model (bool): Flag to select whether to use compiled\n",
      " |              (optimized) model. Default: False.\n",
      " |          wait (bool): Whether the call should wait until the deployment of\n",
      " |              model completes (default: True).\n",
      " |          model_name (str): Name to use for creating an Amazon SageMaker\n",
      " |              model. If not specified, the estimator generates a default job name\n",
      " |              based on the training image name and current timestamp.\n",
      " |          kms_key (str): The ARN of the KMS key that is used to encrypt the\n",
      " |              data on the storage volume attached to the instance hosting the\n",
      " |              endpoint.\n",
      " |          data_capture_config (sagemaker.model_monitor.DataCaptureConfig): Specifies\n",
      " |              configuration related to Endpoint data capture for use with\n",
      " |              Amazon SageMaker Model Monitoring. Default: None.\n",
      " |          async_inference_config (sagemaker.model_monitor.AsyncInferenceConfig): Specifies\n",
      " |              configuration related to async inference. Use this configuration when trying\n",
      " |              to create async endpoint and make async inference. If empty config object\n",
      " |              passed through, will use default config to deploy async endpoint. Deploy a\n",
      " |              real-time endpoint if it's None. (default: None)\n",
      " |          serverless_inference_config (sagemaker.serverless.ServerlessInferenceConfig):\n",
      " |              Specifies configuration related to serverless endpoint. Use this configuration\n",
      " |              when trying to create serverless endpoint and make serverless inference. If\n",
      " |              empty object passed through, will use pre-defined values in\n",
      " |              ``ServerlessInferenceConfig`` class to deploy serverless endpoint. Deploy an\n",
      " |              instance based endpoint if it's None. (default: None)\n",
      " |          tags(List[dict[str, str]]): Optional. The list of tags to attach to this specific\n",
      " |              endpoint. Example:\n",
      " |              >>> tags = [{'Key': 'tagname', 'Value': 'tagvalue'}]\n",
      " |              For more information about tags, see\n",
      " |              https://boto3.amazonaws.com/v1/documentation                /api/latest/reference/services/sagemaker.html#SageMaker.Client.add_tags\n",
      " |          **kwargs: Passed to invocation of ``create_model()``.\n",
      " |              Implementations may customize ``create_model()`` to accept\n",
      " |              ``**kwargs`` to customize model creation during deploy.\n",
      " |              For more, see the implementation docs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          sagemaker.predictor.Predictor: A predictor that provides a ``predict()`` method,\n",
      " |              which can be used to send requests to the Amazon SageMaker\n",
      " |              endpoint and obtain inferences.\n",
      " |  \n",
      " |  disable_profiling(self)\n",
      " |      Update the current training job in progress to disable profiling.\n",
      " |      \n",
      " |      Debugger stops collecting the system and framework metrics\n",
      " |      and turns off the Debugger built-in monitoring and profiling rules.\n",
      " |  \n",
      " |  enable_default_profiling(self)\n",
      " |      Update training job to enable Debugger monitoring.\n",
      " |      \n",
      " |      This method enables Debugger monitoring with\n",
      " |      the default ``profiler_config`` parameter to collect system\n",
      " |      metrics and the default built-in ``profiler_report`` rule.\n",
      " |      Framework metrics won't be saved.\n",
      " |      To update training job to emit framework metrics, you can use\n",
      " |      :class:`~sagemaker.estimator.Estimator.update_profiler`\n",
      " |      method and specify the framework metrics you want to enable.\n",
      " |      \n",
      " |      This method is callable when the training job is in progress while\n",
      " |      Debugger monitoring is disabled.\n",
      " |  \n",
      " |  enable_network_isolation(self)\n",
      " |      Return True if this Estimator will need network isolation to run.\n",
      " |      \n",
      " |      Returns:\n",
      " |          bool: Whether this Estimator needs network isolation or not.\n",
      " |  \n",
      " |  fit(self, inputs: Union[str, Dict, sagemaker.inputs.TrainingInput, sagemaker.inputs.FileSystemInput, NoneType] = None, wait: bool = True, logs: str = 'All', job_name: Union[str, NoneType] = None, experiment_config: Union[Dict[str, str], NoneType] = None)\n",
      " |      Train a model using the input training dataset.\n",
      " |      \n",
      " |      The API calls the Amazon SageMaker CreateTrainingJob API to start\n",
      " |      model training. The API uses configuration you provided to create the\n",
      " |      estimator and the specified input training data to send the\n",
      " |      CreatingTrainingJob request to Amazon SageMaker.\n",
      " |      \n",
      " |      This is a synchronous operation. After the model training\n",
      " |      successfully completes, you can call the ``deploy()`` method to host the\n",
      " |      model using the Amazon SageMaker hosting services.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs (str or dict or sagemaker.inputs.TrainingInput or\n",
      " |              sagemaker.inputs.FileSystemInput): Information about the training data.\n",
      " |              This can be one of four types:\n",
      " |      \n",
      " |              * (str) the S3 location where training data is saved, or a file:// path in\n",
      " |                  local mode.\n",
      " |              * (dict[str, str] or dict[str, sagemaker.inputs.TrainingInput] or\n",
      " |                  dict[str, sagemaker.inputs.FileSystemInput]) If using multiple channels for\n",
      " |                  training data, you can specify a dict mapping channel names to strings or\n",
      " |                  :func:`~sagemaker.inputs.TrainingInput` objects or\n",
      " |                  :func:`~sagemaker.inputs.FileSystemInput` objects.\n",
      " |              * (sagemaker.inputs.TrainingInput) - channel configuration for S3 data sources\n",
      " |                  that can provide additional information as well as the path to the training\n",
      " |                  dataset.\n",
      " |                  See :func:`sagemaker.inputs.TrainingInput` for full details.\n",
      " |              * (sagemaker.inputs.FileSystemInput) - channel configuration for\n",
      " |                  a file system data source that can provide additional information as well as\n",
      " |                  the path to the training dataset.\n",
      " |      \n",
      " |          wait (bool): Whether the call should wait until the job completes (default: True).\n",
      " |          logs ([str]): A list of strings specifying which logs to print. Acceptable\n",
      " |              strings are \"All\", \"None\", \"Training\", or \"Rules\". To maintain backwards\n",
      " |              compatibility, boolean values are also accepted and converted to strings.\n",
      " |              Only meaningful when wait is True.\n",
      " |          job_name (str): Training job name. If not specified, the estimator generates\n",
      " |              a default job name based on the training image name and current timestamp.\n",
      " |          experiment_config (dict[str, str]): Experiment management configuration.\n",
      " |              Optionally, the dict can contain three keys:\n",
      " |              'ExperimentName', 'TrialName', and 'TrialComponentDisplayName'.\n",
      " |              The behavior of setting these keys is as follows:\n",
      " |              * If `ExperimentName` is supplied but `TrialName` is not a Trial will be\n",
      " |              automatically created and the job's Trial Component associated with the Trial.\n",
      " |              * If `TrialName` is supplied and the Trial already exists the job's Trial Component\n",
      " |              will be associated with the Trial.\n",
      " |              * If both `ExperimentName` and `TrialName` are not supplied the trial component\n",
      " |              will be unassociated.\n",
      " |              * `TrialComponentDisplayName` is used for display in Studio.\n",
      " |              * Both `ExperimentName` and `TrialName` will be ignored if the Estimator instance\n",
      " |              is built with :class:`~sagemaker.workflow.pipeline_context.PipelineSession`.\n",
      " |              However, the value of `TrialComponentDisplayName` is honored for display in Studio.\n",
      " |      Returns:\n",
      " |          None or pipeline step arguments in case the Estimator instance is built with\n",
      " |          :class:`~sagemaker.workflow.pipeline_context.PipelineSession`\n",
      " |  \n",
      " |  get_vpc_config(self, vpc_config_override='VPC_CONFIG_DEFAULT')\n",
      " |      Returns VpcConfig dict either from this Estimator's subnets and security groups.\n",
      " |      \n",
      " |      Or else validate and return an optional override value.\n",
      " |      \n",
      " |      Args:\n",
      " |          vpc_config_override:\n",
      " |  \n",
      " |  latest_job_debugger_artifacts_path(self)\n",
      " |      Gets the path to the DebuggerHookConfig output artifacts.\n",
      " |      \n",
      " |      Returns:\n",
      " |          str: An S3 path to the output artifacts.\n",
      " |  \n",
      " |  latest_job_profiler_artifacts_path(self)\n",
      " |      Gets the path to the profiling output artifacts.\n",
      " |      \n",
      " |      Returns:\n",
      " |          str: An S3 path to the output artifacts.\n",
      " |  \n",
      " |  latest_job_tensorboard_artifacts_path(self)\n",
      " |      Gets the path to the TensorBoardOutputConfig output artifacts.\n",
      " |      \n",
      " |      Returns:\n",
      " |          str: An S3 path to the output artifacts.\n",
      " |  \n",
      " |  logs(self)\n",
      " |      Display the logs for Estimator's training job.\n",
      " |      \n",
      " |      If the output is a tty or a Jupyter cell, it will be color-coded based\n",
      " |      on which instance the log entry is from.\n",
      " |  \n",
      " |  prepare_workflow_for_training(self, job_name=None)\n",
      " |      Calls _prepare_for_training. Used when setting up a workflow.\n",
      " |      \n",
      " |      Args:\n",
      " |          job_name (str): Name of the training job to be created. If not\n",
      " |              specified, one is generated, using the base name given to the\n",
      " |              constructor if applicable.\n",
      " |  \n",
      " |  register(self, content_types, response_types, inference_instances=None, transform_instances=None, image_uri=None, model_package_name=None, model_package_group_name=None, model_metrics=None, metadata_properties=None, marketplace_cert=False, approval_status=None, description=None, compile_model_family=None, model_name=None, drift_check_baselines=None, customer_metadata_properties=None, domain=None, sample_payload_url=None, task=None, framework=None, framework_version=None, nearest_model_name=None, data_input_configuration=None, **kwargs)\n",
      " |      Creates a model package for creating SageMaker models or listing on Marketplace.\n",
      " |      \n",
      " |      Args:\n",
      " |          content_types (list): The supported MIME types for the input data.\n",
      " |          response_types (list): The supported MIME types for the output data.\n",
      " |          inference_instances (list): A list of the instance types that are used to\n",
      " |              generate inferences in real-time (default: None).\n",
      " |          transform_instances (list): A list of the instance types on which a transformation\n",
      " |              job can be run or on which an endpoint can be deployed (default: None).\n",
      " |          image_uri (str): The container image uri for Model Package, if not specified,\n",
      " |              Estimator's training container image will be used (default: None).\n",
      " |          model_package_name (str): Model Package name, exclusive to `model_package_group_name`,\n",
      " |              using `model_package_name` makes the Model Package un-versioned (default: None).\n",
      " |          model_package_group_name (str): Model Package Group name, exclusive to\n",
      " |              `model_package_name`, using `model_package_group_name` makes the Model Package\n",
      " |              versioned (default: None).\n",
      " |          model_metrics (ModelMetrics): ModelMetrics object (default: None).\n",
      " |          metadata_properties (MetadataProperties): MetadataProperties (default: None).\n",
      " |          marketplace_cert (bool): A boolean value indicating if the Model Package is certified\n",
      " |              for AWS Marketplace (default: False).\n",
      " |          approval_status (str): Model Approval Status, values can be \"Approved\", \"Rejected\",\n",
      " |              or \"PendingManualApproval\" (default: \"PendingManualApproval\").\n",
      " |          description (str): Model Package description (default: None).\n",
      " |          compile_model_family (str): Instance family for compiled model, if specified, a compiled\n",
      " |              model will be used (default: None).\n",
      " |          model_name (str): User defined model name (default: None).\n",
      " |          drift_check_baselines (DriftCheckBaselines): DriftCheckBaselines object (default: None).\n",
      " |          customer_metadata_properties (dict[str, str]): A dictionary of key-value paired\n",
      " |              metadata properties (default: None).\n",
      " |          domain (str): Domain values can be \"COMPUTER_VISION\", \"NATURAL_LANGUAGE_PROCESSING\",\n",
      " |              \"MACHINE_LEARNING\" (default: None).\n",
      " |          sample_payload_url (str): The S3 path where the sample payload is stored\n",
      " |              (default: None).\n",
      " |          task (str): Task values which are supported by Inference Recommender are \"FILL_MASK\",\n",
      " |              \"IMAGE_CLASSIFICATION\", \"OBJECT_DETECTION\", \"TEXT_GENERATION\", \"IMAGE_SEGMENTATION\",\n",
      " |              \"CLASSIFICATION\", \"REGRESSION\", \"OTHER\" (default: None).\n",
      " |          framework (str): Machine learning framework of the model package container image\n",
      " |              (default: None).\n",
      " |          framework_version (str): Framework version of the Model Package Container Image\n",
      " |              (default: None).\n",
      " |          nearest_model_name (str): Name of a pre-trained machine learning benchmarked by\n",
      " |              Amazon SageMaker Inference Recommender (default: None).\n",
      " |          data_input_configuration (str): Input object for the model (default: None).\n",
      " |          **kwargs: Passed to invocation of ``create_model()``. Implementations may customize\n",
      " |              ``create_model()`` to accept ``**kwargs`` to customize model creation during\n",
      " |              deploy. For more, see the implementation docs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          str: A string of SageMaker Model Package ARN.\n",
      " |  \n",
      " |  transformer(self, instance_count, instance_type, strategy=None, assemble_with=None, output_path=None, output_kms_key=None, accept=None, env=None, max_concurrent_transforms=None, max_payload=None, tags=None, role=None, volume_kms_key=None, vpc_config_override='VPC_CONFIG_DEFAULT', enable_network_isolation=None, model_name=None)\n",
      " |      Return a ``Transformer`` that uses a SageMaker Model based on the training job.\n",
      " |      \n",
      " |      It reuses the SageMaker Session and base job name used by\n",
      " |      the Estimator.\n",
      " |      \n",
      " |      Args:\n",
      " |          instance_count (int): Number of EC2 instances to use.\n",
      " |          instance_type (str): Type of EC2 instance to use, for example,\n",
      " |              'ml.c4.xlarge'.\n",
      " |          strategy (str): The strategy used to decide how to batch records in\n",
      " |              a single request (default: None). Valid values: 'MultiRecord'\n",
      " |              and 'SingleRecord'.\n",
      " |          assemble_with (str): How the output is assembled (default: None).\n",
      " |              Valid values: 'Line' or 'None'.\n",
      " |          output_path (str): S3 location for saving the transform result. If\n",
      " |              not specified, results are stored to a default bucket.\n",
      " |          output_kms_key (str): Optional. KMS key ID for encrypting the\n",
      " |              transform output (default: None).\n",
      " |          accept (str): The accept header passed by the client to\n",
      " |              the inference endpoint. If it is supported by the endpoint,\n",
      " |              it will be the format of the batch transform output.\n",
      " |          env (dict): Environment variables to be set for use during the\n",
      " |              transform job (default: None).\n",
      " |          max_concurrent_transforms (int): The maximum number of HTTP requests\n",
      " |              to be made to each individual transform container at one time.\n",
      " |          max_payload (int): Maximum size of the payload in a single HTTP\n",
      " |              request to the container in MB.\n",
      " |          tags (list[dict]): List of tags for labeling a transform job. If\n",
      " |              none specified, then the tags used for the training job are used\n",
      " |              for the transform job.\n",
      " |          role (str): The ``ExecutionRoleArn`` IAM Role ARN for the ``Model``,\n",
      " |              which is also used during transform jobs. If not specified, the\n",
      " |              role from the Estimator will be used.\n",
      " |          volume_kms_key (str): Optional. KMS key ID for encrypting the volume\n",
      " |              attached to the ML compute instance (default: None).\n",
      " |          vpc_config_override (dict[str, list[str]]): Optional override for the\n",
      " |              VpcConfig set on the model.\n",
      " |              Default: use subnets and security groups from this Estimator.\n",
      " |      \n",
      " |              * 'Subnets' (list[str]): List of subnet ids.\n",
      " |              * 'SecurityGroupIds' (list[str]): List of security group ids.\n",
      " |      \n",
      " |          enable_network_isolation (bool): Specifies whether container will\n",
      " |              run in network isolation mode. Network isolation mode restricts\n",
      " |              the container access to outside networks (such as the internet).\n",
      " |              The container does not make any inbound or outbound network\n",
      " |              calls. If True, a channel named \"code\" will be created for any\n",
      " |              user entry script for inference. Also known as Internet-free mode.\n",
      " |              If not specified, this setting is taken from the estimator's\n",
      " |              current configuration.\n",
      " |          model_name (str): Name to use for creating an Amazon SageMaker\n",
      " |              model. If not specified, the estimator generates a default job name\n",
      " |              based on the training image name and current timestamp.\n",
      " |  \n",
      " |  update_profiler(self, rules=None, system_monitor_interval_millis=None, s3_output_path=None, framework_profile_params=None, disable_framework_metrics=False)\n",
      " |      Update training jobs to enable profiling.\n",
      " |      \n",
      " |      This method updates the ``profiler_config`` parameter\n",
      " |      and initiates Debugger built-in rules for profiling.\n",
      " |      \n",
      " |      Args:\n",
      " |          rules (list[:class:`~sagemaker.debugger.ProfilerRule`]): A list of\n",
      " |              :class:`~sagemaker.debugger.ProfilerRule` objects to define\n",
      " |              rules for continuous analysis with SageMaker Debugger. Currently, you can\n",
      " |              only add new profiler rules during the training job. (default: None)\n",
      " |          s3_output_path (str): The location in S3 to store the output. If profiler is enabled\n",
      " |              once, s3_output_path cannot be changed. (default: None)\n",
      " |          system_monitor_interval_millis (int): How often profiling system metrics are\n",
      " |              collected; Unit: Milliseconds (default: None)\n",
      " |          framework_profile_params (:class:`~sagemaker.debugger.FrameworkProfile`):\n",
      " |              A parameter object for framework metrics profiling. Configure it using\n",
      " |              the :class:`~sagemaker.debugger.FrameworkProfile` class.\n",
      " |              To use the default framework profile parameters, pass ``FrameworkProfile()``.\n",
      " |              For more information about the default values,\n",
      " |              see :class:`~sagemaker.debugger.FrameworkProfile`. (default: None)\n",
      " |          disable_framework_metrics (bool): Specify whether to disable all the framework metrics.\n",
      " |              This won't update system metrics and the Debugger built-in rules for monitoring.\n",
      " |              To stop both monitoring and profiling,\n",
      " |              use the :class:`~sagemaker.estimator.Estimator.desable_profiling`\n",
      " |              method. (default: ``False``)\n",
      " |      \n",
      " |      .. attention::\n",
      " |      \n",
      " |          Updating the profiling configuration for TensorFlow dataloader profiling\n",
      " |          is currently not available. If you started a TensorFlow training job only with\n",
      " |          monitoring and want to enable profiling while the training job is running,\n",
      " |          the dataloader profiling cannot be updated.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from EstimatorBase:\n",
      " |  \n",
      " |  attach(training_job_name, sagemaker_session=None, model_channel_name='model') from abc.ABCMeta\n",
      " |      Attach to an existing training job.\n",
      " |      \n",
      " |      Create an Estimator bound to an existing training job, each subclass\n",
      " |      is responsible to implement\n",
      " |      ``_prepare_init_params_from_job_description()`` as this method delegates\n",
      " |      the actual conversion of a training job description to the arguments\n",
      " |      that the class constructor expects. After attaching, if the training job\n",
      " |      has a Complete status, it can be ``deploy()`` ed to create a SageMaker\n",
      " |      Endpoint and return a ``Predictor``.\n",
      " |      \n",
      " |      If the training job is in progress, attach will block until the training job\n",
      " |      completes, but logs of the training job will not display. To see the logs\n",
      " |      content, please call ``logs()``\n",
      " |      \n",
      " |      Examples:\n",
      " |          >>> my_estimator.fit(wait=False)\n",
      " |          >>> training_job_name = my_estimator.latest_training_job.name\n",
      " |          Later on:\n",
      " |          >>> attached_estimator = Estimator.attach(training_job_name)\n",
      " |          >>> attached_estimator.logs()\n",
      " |          >>> attached_estimator.deploy()\n",
      " |      \n",
      " |      Args:\n",
      " |          training_job_name (str): The name of the training job to attach to.\n",
      " |          sagemaker_session (sagemaker.session.Session): Session object which\n",
      " |              manages interactions with Amazon SageMaker APIs and any other\n",
      " |              AWS services needed. If not specified, the estimator creates one\n",
      " |              using the default AWS configuration chain.\n",
      " |          model_channel_name (str): Name of the channel where pre-trained\n",
      " |              model data will be downloaded (default: 'model'). If no channel\n",
      " |              with the same name exists in the training job, this option will\n",
      " |              be ignored.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Instance of the calling ``Estimator`` Class with the attached\n",
      " |          training job.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from EstimatorBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  model_data\n",
      " |      str: The model location in S3. Only set if Estimator has been ``fit()``.\n",
      " |  \n",
      " |  training_job_analytics\n",
      " |      Return a ``TrainingJobAnalytics`` object for the current training job.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from EstimatorBase:\n",
      " |  \n",
      " |  CONTAINER_CODE_CHANNEL_SOURCEDIR_PATH = '/opt/ml/input/data/code/sourc...\n",
      " |  \n",
      " |  INSTANCE_TYPE = 'sagemaker_instance_type'\n",
      " |  \n",
      " |  JOB_CLASS_NAME = 'training-job'\n",
      " |  \n",
      " |  LAUNCH_MPI_ENV_NAME = 'sagemaker_mpi_enabled'\n",
      " |  \n",
      " |  LAUNCH_PS_ENV_NAME = 'sagemaker_parameter_server_enabled'\n",
      " |  \n",
      " |  LAUNCH_SM_DDP_ENV_NAME = 'sagemaker_distributed_dataparallel_enabled'\n",
      " |  \n",
      " |  MPI_CUSTOM_MPI_OPTIONS = 'sagemaker_mpi_custom_mpi_options'\n",
      " |  \n",
      " |  MPI_NUM_PROCESSES_PER_HOST = 'sagemaker_mpi_num_of_processes_per_host'\n",
      " |  \n",
      " |  SM_DDP_CUSTOM_MPI_OPTIONS = 'sagemaker_distributed_dataparallel_custom...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(img_classifier_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Great, now we can train the model using the model_inputs. In the cell below, call the `fit` method on our model,:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-25 02:29:54 Starting - Starting the training job."
     ]
    }
   ],
   "source": [
    "## TODO: train your model\n",
    "img_classifier_model.fit(inputs=model_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all goes well, you'll end up with a model topping out above `.8` validation accuracy. With only 1000 training samples in the CIFAR dataset, that's pretty good. We could definitely pursue data augmentation & gathering more samples to help us improve further, but for now let's proceed to deploy our model.\n",
    "\n",
    "### Getting ready to deploy\n",
    "\n",
    "To begin with, let's configure Model Monitor to track our deployment. We'll define a `DataCaptureConfig` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    ## TODO: Set config options\n",
    "    destination_s3_uri=f\"s3://{bucket}/data_capture\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `destination_s3_uri` parameter: At the end of the project, we can explore the `data_capture` directory in S3 to find crucial data about the inputs and outputs Model Monitor has observed on our model endpoint over time.\n",
    "\n",
    "With that done, deploy your model on a single `ml.m5.xlarge` instance with the data capture config attached:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = img_classifier_model.deploy(\n",
    "    ## TODO: fill in deployment options\n",
    "    data_capture_config=data_capture_config\n",
    "    )\n",
    "\n",
    "endpoint = deployment.endpoint_name\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the endpoint name for later as well.\n",
    "\n",
    "Next, instantiate a Predictor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ## TODO: fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code snippet below we are going to prepare one of your saved images for prediction. Use the predictor to process the `payload`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import IdentitySerializer\n",
    "import base64\n",
    "\n",
    "predictor.serializer = IdentitySerializer(\"image/png\")\n",
    "with open(\"./test/bicycle_s_001789.png\", \"rb\") as f:\n",
    "    payload = f.read()\n",
    "\n",
    "    \n",
    "inference = ## TODO: Process the payload with your predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your `inference` object is an array of two values, the predicted probability value for each of your classes (bicycle and motorcycle respectively.) So, for example, a value of `b'[0.91, 0.09]'` indicates the probability of being a bike is 91% and being a motorcycle is 9%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draft Lambdas and Step Function Workflow\n",
    "\n",
    "Your operations team uses Step Functions to orchestrate serverless workflows. One of the nice things about Step Functions is that [workflows can call other workflows](https://docs.aws.amazon.com/step-functions/latest/dg/connect-stepfunctions.html), so the team can easily plug your workflow into the broader production architecture for Scones Unlimited.\n",
    "\n",
    "In this next stage you're going to write and deploy three Lambda functions, and then use the Step Functions visual editor to chain them together! Our functions are going to work with a simple data object:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"inferences\": [], # Output of predictor.predict\n",
    "    \"s3_key\": \"\", # Source data S3 key\n",
    "    \"s3_bucket\": \"\", # Source data S3 bucket\n",
    "    \"image_data\": \"\"  # base64 encoded string containing the image data\n",
    "}\n",
    "```\n",
    "\n",
    "A good test object that you can use for Lambda tests and Step Function executions, throughout the next section, might look like this:\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"image_data\": \"\",\n",
    "  \"s3_bucket\": MY_BUCKET_NAME, # Fill in with your bucket\n",
    "  \"s3_key\": \"test/bicycle_s_000513.png\"\n",
    "}\n",
    "```\n",
    "\n",
    "Using these fields, your functions can read and write the necessary data to execute your workflow. Let's start with the first function. Your first Lambda function will copy an object from S3, base64 encode it, and then return it to the step function as `image_data` in an event.\n",
    "\n",
    "Go to the Lambda dashboard and create a new Lambda function with a descriptive name like \"serializeImageData\" and select thr 'Python 3.8' runtime. Add the same permissions as the SageMaker role you created earlier. (Reminder: you do this in the Configuration tab under \"Permissions\"). Once you're ready, use the starter code below to craft your Lambda handler:\n",
    "\n",
    "```python\n",
    "import json\n",
    "import boto3\n",
    "import base64\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"A function to serialize target data from S3\"\"\"\n",
    "    \n",
    "    # Get the s3 address from the Step Function event input\n",
    "    key = ## TODO: fill in\n",
    "    bucket = ## TODO: fill in\n",
    "    \n",
    "    # Download the data from s3 to /tmp/image.png\n",
    "    ## TODO: fill in\n",
    "    \n",
    "    # We read the data from a file\n",
    "    with open(\"/tmp/image.png\", \"rb\") as f:\n",
    "        image_data = base64.b64encode(f.read())\n",
    "\n",
    "    # Pass the data back to the Step Function\n",
    "    print(\"Event:\", event.keys())\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': {\n",
    "            \"image_data\": image_data,\n",
    "            \"s3_bucket\": bucket,\n",
    "            \"s3_key\": key,\n",
    "            \"inferences\": []\n",
    "        }\n",
    "    }\n",
    "```\n",
    "\n",
    "The next function is responsible for the classification part - we're going to take the image output from the previous function, decode it, and then pass inferences back to the the Step Function.\n",
    "\n",
    "Because this Lambda will have runtime dependencies (i.e. the SageMaker SDK) you'll need to package them in your function. *Key reading:* https://docs.aws.amazon.com/lambda/latest/dg/python-package-create.html#python-package-create-with-dependency\n",
    "\n",
    "Create a new Lambda function with the same rights and a descriptive name, then fill in the starter code below for your classifier Lambda.\n",
    "\n",
    "```python\n",
    "import json\n",
    "import sagemaker\n",
    "import base64\n",
    "from sagemaker.serializers import IdentitySerializer\n",
    "\n",
    "# Fill this in with the name of your deployed model\n",
    "ENDPOINT = ## TODO: fill in\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "\n",
    "    # Decode the image data\n",
    "    image = base64.b64decode(## TODO: fill in)\n",
    "\n",
    "    # Instantiate a Predictor\n",
    "    predictor = ## TODO: fill in\n",
    "\n",
    "    # For this model the IdentitySerializer needs to be \"image/png\"\n",
    "    predictor.serializer = IdentitySerializer(\"image/png\")\n",
    "    \n",
    "    # Make a prediction:\n",
    "    inferences = ## TODO: fill in\n",
    "    \n",
    "    # We return the data back to the Step Function    \n",
    "    event[\"inferences\"] = inferences.decode('utf-8')\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps(event)\n",
    "    }\n",
    "```\n",
    "\n",
    "Finally, we need to filter low-confidence inferences. Define a threshold between 1.00 and 0.000 for your model: what is reasonble for you? If the model predicts at `.70` for it's highest confidence label, do we want to pass that inference along to downstream systems? Make one last Lambda function and tee up the same permissions:\n",
    "\n",
    "```python\n",
    "import json\n",
    "\n",
    "\n",
    "THRESHOLD = .93\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \n",
    "    # Grab the inferences from the event\n",
    "    inferences = ## TODO: fill in\n",
    "    \n",
    "    # Check if any values in our inferences are above THRESHOLD\n",
    "    meets_threshold = ## TODO: fill in\n",
    "    \n",
    "    # If our threshold is met, pass our data back out of the\n",
    "    # Step Function, else, end the Step Function with an error\n",
    "    if meets_threshold:\n",
    "        pass\n",
    "    else:\n",
    "        raise(\"THRESHOLD_CONFIDENCE_NOT_MET\")\n",
    "\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps(event)\n",
    "    }\n",
    "```\n",
    "Once you have tested the lambda functions, save the code for each lambda function in a python script called 'lambda.py'.\n",
    "\n",
    "With your lambdas in place, you can use the Step Functions visual editor to construct a workflow that chains them together. In the Step Functions console you'll have the option to author a Standard step function *Visually*.\n",
    "\n",
    "When the visual editor opens, you'll have many options to add transitions in your workflow. We're going to keep it simple and have just one: to invoke Lambda functions. Add three of them chained together. For each one, you'll be able to select the Lambda functions you just created in the proper order, filter inputs and outputs, and give them descriptive names.\n",
    "\n",
    "Make sure that you:\n",
    "\n",
    "1. Are properly filtering the inputs and outputs of your invokations (e.g. `$.body`)\n",
    "2. Take care to remove the error handling from the last function - it's supposed to \"fail loudly\" for your operations colleagues!\n",
    "\n",
    "Take a screenshot of your working step function in action and export the step function as JSON for your submission package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Great! Now you can use the files in `./test` as test files for our workflow. Depending on our threshold, our workflow should reliably pass predictions about images from `./test` on to downstream systems, while erroring out for inferences below our confidence threshold!\n",
    "\n",
    "### Testing and Evaluation\n",
    "\n",
    "Do several step function invokations using data from the `./test` folder. This process should give you confidence that the workflow both *succeeds* AND *fails* as expected. In addition, SageMaker Model Monitor will generate recordings of your data and inferences which we can visualize.\n",
    "\n",
    "Here's a function that can help you generate test inputs for your invokations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "\n",
    "def generate_test_case():\n",
    "    # Setup s3 in boto3\n",
    "    s3 = boto3.resource('s3')\n",
    "    \n",
    "    # Randomly pick from sfn or test folders in our bucket\n",
    "    objects = s3.Bucket(bucket).objects.filter(\"test\")\n",
    "    \n",
    "    # Grab any random object key from that folder!\n",
    "    obj = random.choice([x.key for x in objects])\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"image_data\": \"\",\n",
    "        \"s3_bucket\": bucket,\n",
    "        \"s3_key\": obj\n",
    "    })\n",
    "generate_test_case()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Step Function dashboard for your new function, you can create new executions and copy in the generated test cases. Do several executions so that you can generate data you can evaluate and visualize.\n",
    "\n",
    "Once you've done several executions, let's visualize the record of our inferences. Pull in the JSONLines data from your inferences like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "# In S3 your data will be saved to a datetime-aware path\n",
    "# Find a path related to a datetime you're interested in\n",
    "data_path = ## TODO: fill in the path to your captured data\n",
    "\n",
    "S3Downloader.download(data_path, \"captured_data\")\n",
    "\n",
    "# Feel free to repeat this multiple times and pull in more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are in JSONLines format, where multiple valid JSON objects are stacked on top of eachother in a single `jsonl` file. We'll import an open-source library, `jsonlines` that was purpose built for parsing this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jsonlines\n",
    "import jsonlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can extract the data from each of the source files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# List the file names we downloaded\n",
    "file_handles = os.listdir(\"./captured_data\")\n",
    "\n",
    "# Dump all the data into an array\n",
    "json_data = []\n",
    "for jsonl in file_handles:\n",
    "    with jsonlines.open(f\"./captured_data/{jsonl}\") as f:\n",
    "        json_data.append(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data should now be a list of dictionaries, with significant nesting. We'll give you an example of some code that grabs data out of the objects and visualizes it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how we'll get our data\n",
    "def simple_getter(obj):\n",
    "    inferences = obj[\"captureData\"][\"endpointOutput\"][\"data\"]\n",
    "    timestamp = obj[\"eventMetadata\"][\"inferenceTime\"]\n",
    "    return json.loads(inferences), timestamp\n",
    "\n",
    "simple_getter(json_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, here's an example of a visualization you can build with this data. In this last part, you will take some time and build your own - the captured data has the input images, the resulting inferences, and the timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the data for the x and y axis\n",
    "x = []\n",
    "y = []\n",
    "for obj in json_data:\n",
    "    inference, timestamp = simple_getter(obj)\n",
    "    \n",
    "    y.append(max(inference))\n",
    "    x.append(timestamp)\n",
    "\n",
    "# Todo: here is an visualization example, take some time to build another visual that helps monitor the result\n",
    "# Plot the data\n",
    "plt.scatter(x, y, c=['r' if k<.94 else 'b' for k in y ])\n",
    "plt.axhline(y=0.94, color='g', linestyle='--')\n",
    "plt.ylim(bottom=.88)\n",
    "\n",
    "# Add labels\n",
    "plt.ylabel(\"Confidence\")\n",
    "plt.suptitle(\"Observed Recent Inferences\", size=14)\n",
    "plt.title(\"Pictured with confidence threshold for production use\", size=10)\n",
    "\n",
    "# Give it some pizzaz!\n",
    "plt.style.use(\"Solarize_Light2\")\n",
    "plt.gcf().autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo: build your own visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations!\n",
    "\n",
    "You've reached the end of the project. In this project you created an event-drivent ML workflow that can be incorporated into the Scones Unlimited production architecture. You used the SageMaker Estimator API to deploy your SageMaker Model and Endpoint, and you used AWS Lambda and Step Functions to orchestrate your ML workflow. Using SageMaker Model Monitor, you instrumented and observed your Endpoint, and at the end of the project you built a visualization to help stakeholders understand the performance of the Endpoint over time. If you're up for it, you can even go further with these stretch goals:\n",
    "\n",
    "* Extend your workflow to incorporate more classes: the CIFAR dataset includes other vehicles that Scones Unlimited can identify with this model.\n",
    "* Modify your event driven workflow: can you rewrite your Lambda functions so that the workflow can process multiple image inputs in parallel? Can the Step Function \"fan out\" to accomodate this new workflow?\n",
    "* Consider the test data generator we provided for you. Can we use it to create a \"dummy data\" generator, to simulate a continuous stream of input data? Or a big paralell load of data?\n",
    "* What if we want to get notified every time our step function errors out? Can we use the Step Functions visual editor in conjunction with a service like SNS to accomplish this? Try it out!\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
